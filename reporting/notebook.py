"""
Jupyter notebook generation for automated reports.

Creates reproducible analysis notebooks from BioAgent results.
"""

import json
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Any


@dataclass
class NotebookCell:
    """A single notebook cell."""

    cell_type: str  # "code" or "markdown"
    source: str | list[str]
    metadata: dict = field(default_factory=dict)
    outputs: list = field(default_factory=list)
    execution_count: int | None = None

    def to_dict(self) -> dict:
        """Convert to notebook format dict."""
        cell = {
            "cell_type": self.cell_type,
            "metadata": self.metadata,
            "source": self.source if isinstance(self.source, list) else self.source.split("\n"),
        }

        if self.cell_type == "code":
            cell["outputs"] = self.outputs
            cell["execution_count"] = self.execution_count

        return cell


class NotebookGenerator:
    """
    Generate Jupyter notebooks from analysis results.

    Creates structured, reproducible notebooks with:
    - Setup cells with imports
    - Data loading
    - Analysis code
    - Visualization
    - Results summary
    """

    def __init__(
        self,
        title: str = "BioAgent Analysis Report",
        author: str = "BioAgent",
        kernel: str = "python3",
    ):
        """
        Initialize the notebook generator.

        Args:
            title: Notebook title
            author: Author name
            kernel: Jupyter kernel name
        """
        self.title = title
        self.author = author
        self.kernel = kernel
        self.cells: list[NotebookCell] = []
        self.metadata = {
            "kernelspec": {
                "display_name": "Python 3",
                "language": "python",
                "name": kernel,
            },
            "language_info": {
                "name": "python",
                "version": "3.10.0",
            },
        }

    def add_markdown(self, content: str, **kwargs) -> "NotebookGenerator":
        """Add a markdown cell."""
        self.cells.append(NotebookCell(
            cell_type="markdown",
            source=content,
            metadata=kwargs.get("metadata", {}),
        ))
        return self

    def add_code(
        self,
        code: str,
        outputs: list | None = None,
        execution_count: int | None = None,
        **kwargs,
    ) -> "NotebookGenerator":
        """Add a code cell."""
        self.cells.append(NotebookCell(
            cell_type="code",
            source=code,
            outputs=outputs or [],
            execution_count=execution_count,
            metadata=kwargs.get("metadata", {}),
        ))
        return self

    def add_title_cell(self) -> "NotebookGenerator":
        """Add title and metadata cell."""
        content = f"""# {self.title}

**Author:** {self.author}
**Date:** {datetime.now().strftime('%Y-%m-%d %H:%M')}
**Generated by:** BioAgent

---
"""
        return self.add_markdown(content)

    def add_setup_cell(
        self,
        packages: list[str] | None = None,
        extra_imports: str = "",
    ) -> "NotebookGenerator":
        """Add standard setup/import cell."""
        if packages is None:
            packages = [
                "numpy as np",
                "pandas as pd",
                "matplotlib.pyplot as plt",
                "seaborn as sns",
            ]

        imports = "\n".join([f"import {pkg}" for pkg in packages])

        code = f"""# Setup and imports
{imports}
{extra_imports}

# Configure plotting
plt.style.use('seaborn-v0_8-whitegrid')
plt.rcParams['figure.figsize'] = (10, 6)
plt.rcParams['figure.dpi'] = 100

# Display settings
pd.set_option('display.max_columns', 50)
pd.set_option('display.max_rows', 100)

print("Setup complete!")
"""
        return self.add_code(code)

    def add_data_loading(
        self,
        data_path: str,
        variable_name: str = "data",
        file_type: str = "auto",
    ) -> "NotebookGenerator":
        """Add data loading cell."""
        self.add_markdown(f"## Data Loading\n\nLoading data from `{data_path}`")

        if file_type == "auto":
            ext = Path(data_path).suffix.lower()
            file_type = {
                ".csv": "csv",
                ".tsv": "tsv",
                ".txt": "tsv",
                ".xlsx": "excel",
                ".parquet": "parquet",
            }.get(ext, "csv")

        if file_type == "csv":
            code = f'{variable_name} = pd.read_csv("{data_path}")'
        elif file_type == "tsv":
            code = f'{variable_name} = pd.read_csv("{data_path}", sep="\\t")'
        elif file_type == "excel":
            code = f'{variable_name} = pd.read_excel("{data_path}")'
        elif file_type == "parquet":
            code = f'{variable_name} = pd.read_parquet("{data_path}")'
        else:
            code = f'{variable_name} = pd.read_csv("{data_path}")'

        code += f"""

# Preview data
print(f"Data shape: {{{variable_name}.shape}}")
{variable_name}.head()
"""
        return self.add_code(code)

    def add_section(self, title: str, description: str = "") -> "NotebookGenerator":
        """Add a section header."""
        content = f"## {title}"
        if description:
            content += f"\n\n{description}"
        return self.add_markdown(content)

    def add_volcano_plot(
        self,
        data_var: str = "results",
        fc_col: str = "log2FoldChange",
        pval_col: str = "pvalue",
        gene_col: str = "gene",
        fc_threshold: float = 1.0,
        pval_threshold: float = 0.05,
    ) -> "NotebookGenerator":
        """Add volcano plot code."""
        self.add_markdown("### Volcano Plot\n\nVisualize differential expression results.")

        code = f"""# Volcano Plot
import numpy as np

fig, ax = plt.subplots(figsize=(10, 8))

# Calculate -log10(p-value)
neg_log_pval = -np.log10({data_var}['{pval_col}'].clip(lower=1e-300))

# Classify points
up = ({data_var}['{fc_col}'] >= {fc_threshold}) & ({data_var}['{pval_col}'] <= {pval_threshold})
down = ({data_var}['{fc_col}'] <= -{fc_threshold}) & ({data_var}['{pval_col}'] <= {pval_threshold})

# Plot
ax.scatter({data_var}.loc[~(up|down), '{fc_col}'], neg_log_pval[~(up|down)],
           c='gray', alpha=0.5, s=10, label='NS')
ax.scatter({data_var}.loc[up, '{fc_col}'], neg_log_pval[up],
           c='red', alpha=0.7, s=10, label=f'Up ({{up.sum()}})')
ax.scatter({data_var}.loc[down, '{fc_col}'], neg_log_pval[down],
           c='blue', alpha=0.7, s=10, label=f'Down ({{down.sum()}})')

# Thresholds
ax.axhline(-np.log10({pval_threshold}), ls='--', c='gray', lw=0.5)
ax.axvline({fc_threshold}, ls='--', c='gray', lw=0.5)
ax.axvline(-{fc_threshold}, ls='--', c='gray', lw=0.5)

ax.set_xlabel('log₂(Fold Change)')
ax.set_ylabel('-log₁₀(p-value)')
ax.legend()
ax.set_title('Volcano Plot')
plt.tight_layout()
plt.show()

print(f"Up-regulated: {{up.sum()}}")
print(f"Down-regulated: {{down.sum()}}")
"""
        return self.add_code(code)

    def add_heatmap(
        self,
        data_var: str = "expression",
        cluster: bool = True,
    ) -> "NotebookGenerator":
        """Add heatmap code."""
        self.add_markdown("### Heatmap\n\nClustered heatmap of expression values.")

        code = f"""# Heatmap
import seaborn as sns

# Create clustered heatmap
g = sns.clustermap(
    {data_var},
    cmap='RdBu_r',
    center=0,
    figsize=(12, 10),
    row_cluster={cluster},
    col_cluster={cluster},
    xticklabels=True,
    yticklabels=True,
)
g.fig.suptitle('Expression Heatmap', y=1.02)
plt.show()
"""
        return self.add_code(code)

    def add_pca_plot(
        self,
        data_var: str = "expression",
        metadata_var: str = "metadata",
        color_col: str = "condition",
    ) -> "NotebookGenerator":
        """Add PCA plot code."""
        self.add_markdown("### PCA Plot\n\nPrincipal Component Analysis for sample clustering.")

        code = f"""# PCA Plot
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler

# Standardize data
scaler = StandardScaler()
scaled_data = scaler.fit_transform({data_var}.T)  # Samples as rows

# Perform PCA
pca = PCA(n_components=2)
pcs = pca.fit_transform(scaled_data)

# Create plot
fig, ax = plt.subplots(figsize=(10, 8))

# Plot with color by condition
scatter = ax.scatter(
    pcs[:, 0], pcs[:, 1],
    c=pd.Categorical({metadata_var}['{color_col}']).codes,
    cmap='tab10',
    s=100,
    alpha=0.7,
)

# Add labels
for i, sample in enumerate({data_var}.columns):
    ax.annotate(sample, (pcs[i, 0], pcs[i, 1]), fontsize=8)

ax.set_xlabel(f'PC1 ({{pca.explained_variance_ratio_[0]*100:.1f}}%)')
ax.set_ylabel(f'PC2 ({{pca.explained_variance_ratio_[1]*100:.1f}}%)')
ax.set_title('PCA Plot')

# Legend
handles, labels = scatter.legend_elements()
ax.legend(handles, {metadata_var}['{color_col}'].unique())

plt.tight_layout()
plt.show()
"""
        return self.add_code(code)

    def add_summary_statistics(
        self,
        data_var: str = "results",
        pval_col: str = "padj",
        fc_col: str = "log2FoldChange",
    ) -> "NotebookGenerator":
        """Add summary statistics section."""
        self.add_markdown("## Summary Statistics")

        code = f"""# Summary Statistics
print("=== Differential Expression Summary ===")
print(f"Total genes tested: {{len({data_var})}}")

sig = {data_var}['{pval_col}'] < 0.05
up = sig & ({data_var}['{fc_col}'] > 0)
down = sig & ({data_var}['{fc_col}'] < 0)

print(f"Significant (padj < 0.05): {{sig.sum()}}")
print(f"  - Up-regulated: {{up.sum()}}")
print(f"  - Down-regulated: {{down.sum()}}")

# Top genes
print("\\n=== Top 10 Up-regulated Genes ===")
display({data_var}[up].nsmallest(10, '{pval_col}'))

print("\\n=== Top 10 Down-regulated Genes ===")
display({data_var}[down].nsmallest(10, '{pval_col}'))
"""
        return self.add_code(code)

    def add_conclusion(self, text: str = "") -> "NotebookGenerator":
        """Add conclusion section."""
        content = """## Conclusions

"""
        if text:
            content += text
        else:
            content += """*Add your conclusions and interpretation here.*

### Key Findings
-

### Limitations
-

### Next Steps
-
"""
        return self.add_markdown(content)

    def to_dict(self) -> dict:
        """Convert notebook to dict format."""
        return {
            "nbformat": 4,
            "nbformat_minor": 5,
            "metadata": self.metadata,
            "cells": [cell.to_dict() for cell in self.cells],
        }

    def save(self, path: str) -> str:
        """
        Save notebook to file.

        Args:
            path: Output file path

        Returns:
            Absolute path to saved file
        """
        path = Path(path)
        path.parent.mkdir(parents=True, exist_ok=True)

        if not path.suffix:
            path = path.with_suffix(".ipynb")

        with open(path, "w", encoding="utf-8") as f:
            json.dump(self.to_dict(), f, indent=2)

        return str(path.absolute())


def create_analysis_notebook(
    title: str,
    analysis_type: str,
    data_path: str | None = None,
    output_path: str | None = None,
    **kwargs,
) -> str:
    """
    Create a pre-configured analysis notebook.

    Args:
        title: Notebook title
        analysis_type: Type of analysis (deseq2, enrichment, qc, custom)
        data_path: Path to data file
        output_path: Output notebook path
        **kwargs: Additional parameters for the analysis

    Returns:
        Path to saved notebook
    """
    nb = NotebookGenerator(title=title)
    nb.add_title_cell()

    if analysis_type == "deseq2":
        nb.add_setup_cell(extra_imports="""
from scipy import stats
from statsmodels.stats.multitest import multipletests
""")

        if data_path:
            nb.add_data_loading(data_path, "results")

        nb.add_section("Quality Control", "Initial data quality assessment.")
        nb.add_code("""# Check for missing values
print(f"Missing values:\\n{results.isnull().sum()}")

# Distribution of p-values
fig, axes = plt.subplots(1, 2, figsize=(12, 4))
axes[0].hist(results['pvalue'].dropna(), bins=50, edgecolor='black')
axes[0].set_xlabel('p-value')
axes[0].set_title('P-value Distribution')

axes[1].hist(results['log2FoldChange'].dropna(), bins=50, edgecolor='black')
axes[1].set_xlabel('log2 Fold Change')
axes[1].set_title('Fold Change Distribution')
plt.tight_layout()
plt.show()
""")

        nb.add_section("Differential Expression Analysis")
        nb.add_volcano_plot("results")
        nb.add_summary_statistics("results")
        nb.add_conclusion()

    elif analysis_type == "enrichment":
        nb.add_setup_cell(extra_imports="""
# For enrichment analysis
import gseapy as gp
""")

        if data_path:
            nb.add_data_loading(data_path, "enrichment")

        nb.add_section("Enrichment Results")
        nb.add_code("""# Top enriched terms
top_terms = enrichment.nsmallest(20, 'P.value')

fig, ax = plt.subplots(figsize=(10, 8))
ax.barh(range(len(top_terms)), -np.log10(top_terms['P.value']))
ax.set_yticks(range(len(top_terms)))
ax.set_yticklabels(top_terms['Term'])
ax.set_xlabel('-log10(p-value)')
ax.set_title('Top Enriched Terms')
ax.invert_yaxis()
plt.tight_layout()
plt.show()
""")
        nb.add_conclusion()

    elif analysis_type == "qc":
        nb.add_setup_cell()

        nb.add_section("Sample Quality Control")
        nb.add_code("""# QC metrics placeholder
# Add your QC analysis code here
print("QC analysis notebook - add your metrics")
""")
        nb.add_conclusion()

    else:
        # Custom/empty notebook
        nb.add_setup_cell()
        nb.add_section("Analysis", "Add your analysis code below.")
        nb.add_code("# Your analysis code here")
        nb.add_conclusion()

    # Save
    if output_path is None:
        output_path = f"{title.lower().replace(' ', '_')}.ipynb"

    return nb.save(output_path)
